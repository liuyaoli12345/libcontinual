{'data_root': 'D:/codes/NJU/Third_Year/ml/BigHomework/cifar100', 'image_size': 32, 'pin_memory': False, 'augment': True, 'workers': 8, 'device_ids': 0, 'n_gpu': 1, 'seed': 1993, 'deterministic': True, 'epoch': 10, 'batch_size': 128, 'val_per_epoch': 10, 'optimzer': {'name': 'SGD', 'kwargs': {'lr': 0.1}}, 'lr_scheduler': {'name': 'StepLR', 'kwargs': {'gamma': 0.5, 'step_size': 10}}, 'warmup': 3, 'includes': ['headers/data.yaml', 'headers/device.yaml', 'headers/model.yaml', 'headers/optimizer.yaml', 'backbones/resnet12.yaml'], 'save_path': './', 'init_cls_num': 10, 'inc_cls_num': 10, 'task_num': 10, 'optimizer': {'name': 'SGD', 'kwargs': {'lr': 0.1}}, 'backbone': {'name': 'resnet18', 'kwargs': {'num_classes': 100, 'args': {'dataset': 'cifar100'}}}, 'buffer': {'name': 'LinearBuffer', 'kwargs': {'buffer_size': 500, 'batch_size': 32, 'strategy': 'random'}}, 'classifier': {'name': 'LUCIR', 'kwargs': {'num_class': 100, 'feat_dim': 512, 'init_cls_num': 10, 'inc_cls_num': 10, 'dist': 0.5, 'lamda': 10, 'K': 2, 'lw_mr': 1}}, 'rank': 0}
LUCIR(
  (backbone): ResNet(
    (conv1): Sequential(
      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
    )
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (classifier): CosineLinear()
  (loss_fn): CrossEntropyLoss()
)
Trainable params in the model: 11173953
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.03333333333333333
    momentum: 0
    nesterov: False
    weight_decay: 0
)
================Task 0 Start!================
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.03333333333333333
    momentum: 0
    nesterov: False
    weight_decay: 0
)
================Task 0 Training!================
The training samples number: 5000
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/10] |	Loss: 0.000 	Average Acc: 0.181 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/10] |	Loss: 0.000 	Average Acc: 0.312 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/10] |	Loss: 0.000 	Average Acc: 0.416 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/10] |	Loss: 0.000 	Average Acc: 0.512 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/10] |	Loss: 0.000 	Average Acc: 0.592 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/10] |	Loss: 0.000 	Average Acc: 0.660 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/10] |	Loss: 0.000 	Average Acc: 0.730 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/10] |	Loss: 0.000 	Average Acc: 0.790 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/10] |	Loss: 0.000 	Average Acc: 0.854 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/10] |	Loss: 0.000 	Average Acc: 0.910 
================ Test on the test set ================
 * Average Acc: 0.640 Best acc 0.640
 Per-Task Acc:[0.64]
================Task 1 Start!================
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.03333333333333333
    momentum: 0
    nesterov: False
    weight_decay: 0
)
================Task 1 Training!================
The training samples number: 5500
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/10] |	Loss: 0.000 	Average Acc: 0.230 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/10] |	Loss: 0.000 	Average Acc: 0.435 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/10] |	Loss: 0.000 	Average Acc: 0.549 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/10] |	Loss: 0.000 	Average Acc: 0.692 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/10] |	Loss: 0.000 	Average Acc: 0.826 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/10] |	Loss: 0.000 	Average Acc: 0.909 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/10] |	Loss: 0.000 	Average Acc: 0.972 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/10] |	Loss: 0.000 	Average Acc: 0.993 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/10] |	Loss: 0.000 	Average Acc: 0.999 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/10] |	Loss: 0.000 	Average Acc: 0.999 
================ Test on the test set ================
 * Average Acc: 0.465 Best acc 0.465
 Per-Task Acc:[0.43, 0.5]
================Task 2 Start!================
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.03333333333333333
    momentum: 0
    nesterov: False
    weight_decay: 0
)
================Task 2 Training!================
The training samples number: 5500
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/10] |	Loss: 0.000 	Average Acc: 0.389 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/10] |	Loss: 0.000 	Average Acc: 0.658 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/10] |	Loss: 0.000 	Average Acc: 0.769 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/10] |	Loss: 0.000 	Average Acc: 0.917 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/10] |	Loss: 0.000 	Average Acc: 0.981 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/10] |	Loss: 0.000 	Average Acc: 0.997 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/10] |	Loss: 0.000 	Average Acc: 0.999 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/10] |	Loss: 0.000 	Average Acc: 0.999 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/10] |	Loss: 0.000 	Average Acc: 0.999 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/10] |	Loss: 0.000 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.350 Best acc 0.350
 Per-Task Acc:[0.2, 0.16, 0.69]
================Task 3 Start!================
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.03333333333333333
    momentum: 0
    nesterov: False
    weight_decay: 0
)
================Task 3 Training!================
The training samples number: 5500
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/10] |	Loss: 0.000 	Average Acc: 0.398 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/10] |	Loss: 0.000 	Average Acc: 0.634 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/10] |	Loss: 0.000 	Average Acc: 0.745 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/10] |	Loss: 0.000 	Average Acc: 0.918 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/10] |	Loss: 0.000 	Average Acc: 0.983 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/10] |	Loss: 0.000 	Average Acc: 0.996 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/10] |	Loss: 0.000 	Average Acc: 0.999 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/10] |	Loss: 0.000 	Average Acc: 0.999 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/10] |	Loss: 0.000 	Average Acc: 0.999 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/10] |	Loss: 0.000 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.225 Best acc 0.225
 Per-Task Acc:[0.01, 0.02, 0.28, 0.59]
================Task 4 Start!================
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.03333333333333333
    momentum: 0
    nesterov: False
    weight_decay: 0
)
================Task 4 Training!================
The training samples number: 5500
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/10] |	Loss: 0.000 	Average Acc: 0.525 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/10] |	Loss: 0.000 	Average Acc: 0.787 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/10] |	Loss: 0.000 	Average Acc: 0.896 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/10] |	Loss: 0.000 	Average Acc: 0.974 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/10] |	Loss: 0.000 	Average Acc: 0.996 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/10] |	Loss: 0.000 	Average Acc: 0.999 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/10] |	Loss: 0.000 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.214 Best acc 0.214
 Per-Task Acc:[0.0, 0.0, 0.06, 0.28, 0.73]
================Task 5 Start!================
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.03333333333333333
    momentum: 0
    nesterov: False
    weight_decay: 0
)
================Task 5 Training!================
The training samples number: 5500
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/10] |	Loss: 0.000 	Average Acc: 0.464 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/10] |	Loss: 0.000 	Average Acc: 0.671 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/10] |	Loss: 0.000 	Average Acc: 0.786 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/10] |	Loss: 0.000 	Average Acc: 0.948 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/10] |	Loss: 0.000 	Average Acc: 0.994 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/10] |	Loss: 0.000 	Average Acc: 0.999 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/10] |	Loss: 0.000 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.192 Best acc 0.192
 Per-Task Acc:[0.0, 0.0, 0.02, 0.14, 0.4, 0.59]
================Task 6 Start!================
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.03333333333333333
    momentum: 0
    nesterov: False
    weight_decay: 0
)
================Task 6 Training!================
The training samples number: 5500
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/10] |	Loss: 0.000 	Average Acc: 0.463 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/10] |	Loss: 0.000 	Average Acc: 0.699 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/10] |	Loss: 0.000 	Average Acc: 0.840 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/10] |	Loss: 0.000 	Average Acc: 0.966 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/10] |	Loss: 0.000 	Average Acc: 0.996 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/10] |	Loss: 0.000 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.169 Best acc 0.169
 Per-Task Acc:[0.0, 0.0, 0.0, 0.0, 0.17, 0.33, 0.68]
================Task 7 Start!================
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.03333333333333333
    momentum: 0
    nesterov: False
    weight_decay: 0
)
================Task 7 Training!================
The training samples number: 5500
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/10] |	Loss: 0.000 	Average Acc: 0.533 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/10] |	Loss: 0.000 	Average Acc: 0.749 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/10] |	Loss: 0.000 	Average Acc: 0.861 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/10] |	Loss: 0.000 	Average Acc: 0.967 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/10] |	Loss: 0.000 	Average Acc: 0.998 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/10] |	Loss: 0.000 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.148 Best acc 0.148
 Per-Task Acc:[0.0, 0.0, 0.0, 0.0, 0.05, 0.07, 0.37, 0.69]
================Task 8 Start!================
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.03333333333333333
    momentum: 0
    nesterov: False
    weight_decay: 0
)
================Task 8 Training!================
The training samples number: 5500
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/10] |	Loss: 0.000 	Average Acc: 0.524 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/10] |	Loss: 0.000 	Average Acc: 0.740 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/10] |	Loss: 0.000 	Average Acc: 0.892 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/10] |	Loss: 0.000 	Average Acc: 0.980 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/10] |	Loss: 0.000 	Average Acc: 0.998 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/10] |	Loss: 0.000 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.127 Best acc 0.127
 Per-Task Acc:[0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.08, 0.38, 0.67]
================Task 9 Start!================
SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 0.03333333333333333
    momentum: 0
    nesterov: False
    weight_decay: 0
)
================Task 9 Training!================
The training samples number: 5500
learning rate: [0.03333333333333333]
================ Train on the train set ================
Epoch [0/10] |	Loss: 0.000 	Average Acc: 0.486 
learning rate: [0.06666666666666667]
================ Train on the train set ================
Epoch [1/10] |	Loss: 0.000 	Average Acc: 0.699 
learning rate: [0.1]
================ Train on the train set ================
Epoch [2/10] |	Loss: 0.000 	Average Acc: 0.846 
learning rate: [0.1]
================ Train on the train set ================
Epoch [3/10] |	Loss: 0.000 	Average Acc: 0.946 
learning rate: [0.1]
================ Train on the train set ================
Epoch [4/10] |	Loss: 0.000 	Average Acc: 0.993 
learning rate: [0.1]
================ Train on the train set ================
Epoch [5/10] |	Loss: 0.000 	Average Acc: 0.999 
learning rate: [0.1]
================ Train on the train set ================
Epoch [6/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [7/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [8/10] |	Loss: 0.000 	Average Acc: 1.000 
learning rate: [0.1]
================ Train on the train set ================
Epoch [9/10] |	Loss: 0.000 	Average Acc: 1.000 
================ Test on the test set ================
 * Average Acc: 0.116 Best acc 0.116
 Per-Task Acc:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.13, 0.36, 0.66]
Time cost :  1042.013444185257
